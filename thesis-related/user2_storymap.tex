## User persona:
- **Background & Experience:** thirty-something semi-professional musician (e.g. a keyboardist in a local band). Comfortable with common music software (DAWs, synthesizer presets) but not a coder. Has a good grasp of musical concepts and some tech savvy with gear.
- **Goals:** Use IMPSY to **enhance practice sessions and songwriting** – for instance, have the AI riff off his solos to spark new ideas. Possibly integrate the system in live jam sessions or teaching (showing students how AI can be a creative partner). Wants to save sessions and refine the AI over time to better fit his style.
- **Frustrations:** Gets impatient with rigid tools that don’t allow any customization of the music output. If the AI’s responses feel repetitive or off-style, he wants a way to improve it (e.g. by training with more of his own playing). Also dislikes when projects get disorganized – he values being able to manage and reload saved models or recordings easily.
- **Interaction Style:** Exploratory and iterative. Ben will dive a bit deeper into settings than a novice: for example, he’ll explore menu options to train the model on his latest jam, or switch the AI’s instrument sound. However, he still expects **a friendly UI** – he appreciates visual feedback (like graphs of AI learning or live indicators of tempo/beat) and will use moderately advanced features if they are well-explained. He might consult the user guide for specific tasks, but generally prefers learning by doing.

## Scenarios
###  User activities
- **Improving with AI**
- **Managing Projects & AI Style**
- **Understanding AI Behaviour**

###  User tasks
- **For improving with AI:**
    -   Use AI to generate new musical ideas from his solos.
    -   Integrate AI into practice for enhanced sessions.
    -   Explore different AI responses for songwriting.
- **For managing Projects & AI Style:**
    -   Save jam sessions and performance logs easily.
    -   Initiate AI model training from saved sessions.
    -   Access and manage saved projects/models.
    -   Switch AI instrument sounds or basic style.
- **For understanding AI Behaviour:**
    -   View basic performance logs.
    -   See simple indicators of AI learning/training progress.
    -   Explore moderately advanced, well-explained features.

## User stories
###  Release 1: Core Practice Enhancement & Session Saving
- AI Riffing: AI generates musical ideas based on user input.
- Session Save: Save current jam session log with one click.
- Project Dashboard: Basic list of recent sessions.
- Load Project: Reload a previously saved session.
- Basic AI Customisation: Option to change AI instrument sound.
- Style Adaptation: AI shows initial learning from user's playing style.
- Performance Log: Simple timeline view of user's performance.

###  Release 2: AI Training & Project Management
- Model Training: One-click option to train a new AI model from a saved session log.
- Personalised Model: AI's responses start to reflect user's style more distinctly after training.
- Manage Projects: Rename, delete, or organise saved sessions/models.
- Training Feedback: Simple visual indicator of model training progress (e.g., a progress bar).
- Style Refinement: AI offers slightly more nuanced responses post-training.
- UI for Training: Clear, friendly interface for initiating and monitoring training.

###  Release 3: Deeper Insights & Creative Partnership
- Advanced Feature Access: Clearly marked, well-explained moderately advanced settings.
- Learning Visualisation: Basic graphs of training (e.g., simple loss curve if appropriate).
- AI State Insight: Indication of what the AI is currently doing or learning.
- Songwriting Tool: Features that explicitly support using AI for song creation.
- Teaching Aid: Potential to use AI to demonstrate concepts to students.
- Customisation Options: More choices for AI sound or basic behaviour (e.g. intensity).
- Organised Workspace: Efficient management of a growing number of personalised models. 